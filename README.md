# Michaverse AI Tool

## üé¨ Demo Videos

**Instagram**: [Summary](https://www.instagram.com/p/DLwDIhvK2zw/)

**YouTube**: [Full Breakdown](https://www.youtube.com/watch?v=X06M-wwQNo4)

---

## What is this?

This is a modular, self-built AI playground and interface system built entirely in JavaScript and Python. It integrates multiple AI models in a seamless, interactive UI and allows:

Locals (need at least 8GB of VRAM and a NVidia Card)
- Transcription via [Whisper](https://github.com/openai/whisper)
- Text-to-speech via [Zonos](https://github.com/sdbds/Zonos-for-windows)
- Text-to-speech via [Chatterbox](https://github.com/resemble-ai/chatterbox)

APIs
- LLM interaction via OpenAI GPT4.1 & GPT4.1-mini
- Image generation via Google Imagen and OpenAI DALL¬∑E
- Translation via Google Translate

Functionality
- Combined pipelines (STT + Translate + LLM + TTS (with sampled Voices) + Image)
- Personality & voice mapping chosen by LLM
- Seesion & LongTerm Memory handling by LLM
- LLM can initiate Conversations
- Audio normalization via FFmpeg
- Responsive layout with resizable panels

---

## Architecture

- **Frontend**: Vanilla JS + HTML/CSS
- **Backend**: Node.js + Python (via spawn)
- **Models**: OpenAI GPT, Whisper, Zonos, Chatterbox, FFmpeg, Google Imagen, OpenAI DALL¬∑E, Google Translate

---

## Folder Structure

üìÅ ai-tool
‚îú‚îÄ‚îÄ readme.md
‚îú‚îÄ‚îÄ server.js
‚îú‚îÄ‚îÄ nodemon.json
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ package-lock.json
‚îú‚îÄ‚îÄ Audiofiles/
‚îÇ   ‚îî‚îÄ‚îÄ VoiceSample/
‚îú‚îÄ‚îÄ Images/
‚îú‚îÄ‚îÄ Memory/
‚îÇ   ‚îî‚îÄ‚îÄ cost/
‚îÇ       ‚îî‚îÄ‚îÄ cumulativeCosts.json
‚îÇ   ‚îî‚îÄ‚îÄ longTermMemory/
‚îÇ       ‚îî‚îÄ‚îÄ longTermMemory.txt
‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îú‚îÄ‚îÄ audio/
‚îÇ   ‚îú‚îÄ‚îÄ fonts/
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ variables.js
‚îÇ   ‚îú‚îÄ‚îÄ eventListener.js
‚îÇ   ‚îú‚îÄ‚îÄ sideFunctions.js
‚îÇ   ‚îú‚îÄ‚îÄ main.js
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îî‚îÄ‚îÄ style.css
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ _powerShellScripts/
‚îÇ   ‚îú‚îÄ‚îÄ venv-chatterbox/
‚îÇ   ‚îú‚îÄ‚îÄ venv-whisper/
‚îÇ   ‚îú‚îÄ‚îÄ zonos-edited-Scripts/       // Copy content to "repos/Zonos-for-windows/" after cloning and initiating Zonos
‚îÇ   ‚îú‚îÄ‚îÄ chatberbotScript.py
‚îÇ   ‚îú‚îÄ‚îÄ whisperScript.py
‚îÇ   ‚îú‚îÄ‚îÄ StandardVoiceEnglish.wav
‚îÇ   ‚îî‚îÄ‚îÄ StandardVoiceGerman.wav
‚îú‚îÄ‚îÄ repos/
‚îÇ   ‚îî‚îÄ‚îÄ Zonos-for-windows/
‚îú‚îÄ‚îÄ .git/
‚îî‚îÄ‚îÄ node_modules/

---

## Installation

### 1. Clone the repo
```bash
git clone https://github.com/Michaverse/ai-playground.git
cd ai-playground
```

### 2. Integrate lokal Models

Setup Python environment(s)
> Different local AI Models use different Python versions!
Please follow the installation Instructions for each AI Model

You will also need to install CUDA
and PyTorch for each venv (Must be matching your CUDA Version / For me: 2.5.1+cu121)


```bash
# Whisper
activate scripts/venv-whisper/scripts/Activate.ps1
source scripts/venv-whisper/bin/activate
pip install -r requirements-whisper.txt

# Chatterbox
activate scripts/venv-chatterbox/scripts/Activate.ps1
source source scripts/venv-chatterbox/bin/activate
pip install -r requirements-chatterbox.txt
```

#### Zonos
clone the repo to /repos
Overwrite certain scripts after initialising (see scripts/zonos-edited-scripts)

Testing:
```bash
.\scripts\nameOfVenv\Scripts\Activate.ps1
python --version
# Shows Python Version for venv
python -c "import torch; print(torch.version.cuda, torch.cuda.is_available())"
# Shows torch Cuda Version and if it recognized your Graphics Card
```

### 3. Setup `.env` file

For the use of the APIs you will need to have access to Google and OpenAI APIs

Create a `.env` file in the root directory with:
```env
PORT = yourPORT
OPEN_AI_KEY = "yourOpenAIKey"
CAIP_PROJECT_ID = "yourGoogleProjectId"
```

### 4. Launch the tool
```bash
npm install
npm run loop
```

---

## Possible Roadmap

- [ ] API alternatives of Local Models for faster response time
- [ ] Electron Export
- [ ] Upload Images and Files for LLM
- [ ] Let AI talk to itself
- [ ] Bugfix of Text Formatting when sending to Voice Model

---

## Want to collaborate?

If you're a dev, creator or just curious ‚Äî let's connect!
Feel free to open an issue or write me on [Instagram](https://www.instagram.com/michaverse_youtube/) or [YouTube](https://www.youtube.com/@Michaverse).

---

## License

MIT ‚Äì free to use, remix, build upon, just credit and don‚Äôt be evil. ‚ù§Ô∏è